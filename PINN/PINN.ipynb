{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee668f08-5f6d-42d7-992a-b9ab1553d18f",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c633889-ff31-49ed-9cc5-13db613f7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import gc\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler\n",
    "from collections import OrderedDict\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec0aa1-2f8a-40a1-b715-3dce56bac16e",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cbe39-9bbe-4ea9-b4d0-4a48b265edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "f_vort = h5py.File('/storage/p2/parfenyev/PINN/alpha_0.1/vort-prod.h5', 'r')\n",
    "f_velx = h5py.File('/storage/p2/parfenyev/PINN/alpha_0.1/vel-u-prod.h5', 'r')\n",
    "f_vely = h5py.File('/storage/p2/parfenyev/PINN/alpha_0.1/vel-v-prod.h5', 'r')\n",
    "f_p = h5py.File('/storage/p2/parfenyev/PINN/alpha_0.1/p-prod.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b62e7c-f365-457c-91ec-d2e20dd96f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dat_vort = np.array(f_vort['vorticity'])\n",
    "dat_velx = np.array(f_velx['vel-u'])\n",
    "dat_vely = np.array(f_vely['vel-v'])\n",
    "dat_p = np.array(f_p['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84553208-b8b0-4dd9-81ec-e84bc503572e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f252b04-5026-44dc-9f28-3a7fbf7fac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(arr, path, extent=[-np.pi, np.pi, -np.pi, np.pi], title=None, xy=None, w=None, h=None, limit=None):\n",
    "    \n",
    "    # Find correct framesize\n",
    "    buf = io.BytesIO()\n",
    "    plt.imshow(arr[:, :, 0])\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    video = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*\"mp4v\"), 30, (im.size[0], im.size[1]))\n",
    "    \n",
    "    # Make a video\n",
    "    for i in tqdm(range(arr.shape[2])):\n",
    "        fig, ax = plt.subplots()\n",
    "        buf = io.BytesIO()\n",
    "        # extent [horizontal_min,horizontal_max,vertical_min,vertical_max]\n",
    "        img = ax.imshow(arr[:, :, i], cmap=\"seismic\", origin=\"lower\", extent=extent, vmin=-50, vmax=50)\n",
    "        fig.colorbar(img)\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        if xy and w and h:\n",
    "            rect = Rectangle(xy, w, h, linewidth=0, edgecolor='none', facecolor='r')\n",
    "            ax.add_patch(rect)\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        im = Image.open(buf)\n",
    "        mat = np.array(im)\n",
    "        mat = cv2.cvtColor(mat, cv2.COLOR_RGB2BGR)\n",
    "        video.write(mat)\n",
    "        buf.close()\n",
    "        ax.cla()\n",
    "        plt.clf()\n",
    "        plt.close(fig)\n",
    "        if i == limit:\n",
    "            break\n",
    "            \n",
    "    plt.close()\n",
    "    video.release()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a67f9-978f-4778-ae84-5c3ca98efc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(dat_vort, \"./vort_long.mp4\", title=\"vorticity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ec467-7a81-45a8-981a-aa6fca9ff3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "limit = max(abs(np.min(dat_vort[:, :, 0])), abs(np.max(dat_vort[:, :, 0])))\n",
    "img = plt.imshow(dat_vort[:, :, 0], cmap=\"seismic\", origin=\"lower\", extent=[-np.pi, np.pi, -np.pi, np.pi],\n",
    "                vmin=-limit, vmax=limit)\n",
    "ax.set_title(\"Vorticity\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "fig.colorbar(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0babbd-15fc-4823-8967-7ce042a880b7",
   "metadata": {},
   "source": [
    "# Random State Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f4ff5-9d73-4ac2-8b4b-374708bbdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(seed):\n",
    "    np.random.seed(seed=seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "set_random(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98c30a-c5e6-44a9-b093-7875f23962d8",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda02bf-f45c-4467-a1ac-6f862cc15f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.benchmark = True # Find best algo for matrix mult\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946928d-6e88-4226-9d17-d235312366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet for pressure and stream function \n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.Tanh\n",
    "\n",
    "        layer_list = list()\n",
    "        \n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(\n",
    "                (\"layer_%d\" % i, torch.nn.Linear(layers[i], layers[i + 1]))\n",
    "            )\n",
    "            layer_list.append((\"activation_%d\" % i, self.activation()))\n",
    "\n",
    "        layer_list.append(\n",
    "            (\"layer_%d\" % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "\n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers[0](x)\n",
    "        out_in = 0\n",
    "        for i in range(1, len([x for x in self.layers])):\n",
    "            if (i % 4) == 1:\n",
    "                out = self.layers[i](out)\n",
    "                out_in = out\n",
    "            elif (i % 4) == 0:\n",
    "                out = out_in + self.layers[i](out)\n",
    "            else:\n",
    "                out = self.layers[i](out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3731ab-645f-4fed-b737-ce0cdf33b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet for forcing \n",
    "class DNN2(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN2, self).__init__()\n",
    "\n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.Tanh\n",
    "\n",
    "        layer_list = list()\n",
    "        \n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(\n",
    "                (\"layer_%d\" % i, torch.nn.Linear(layers[i], layers[i + 1]))\n",
    "            )\n",
    "            layer_list.append((\"activation_%d\" % i, self.activation()))\n",
    "\n",
    "        layer_list.append(\n",
    "            (\"layer_%d\" % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "\n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers[0](x)\n",
    "        out_in = 0\n",
    "        for i in range(1, len([x for x in self.layers])):\n",
    "            if (i % 4) == 1:\n",
    "                out = self.layers[i](out)\n",
    "                out_in = out\n",
    "            elif (i % 4) == 0:\n",
    "                out = out_in + self.layers[i](out)\n",
    "            else:\n",
    "                out = self.layers[i](out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e688c-5f9b-4c6c-bd22-ebab2dcfac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, x, y, t, u, v, x_eqs, y_eqs, t_eqs, layers_dnn, layers_dnn2, device=\"cpu\", amp=False, weight=1, upd_freq=100):\n",
    "        \n",
    "        # data\n",
    "        self.x = torch.tensor(x, requires_grad=True).float().to(device)\n",
    "        self.y = torch.tensor(y, requires_grad=True).float().to(device)\n",
    "        self.t = torch.tensor(t, requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.v = torch.tensor(v).float().to(device)\n",
    "        \n",
    "        self.U_rms = np.sqrt(np.mean(u**2+v**2))\n",
    "        self.L = np.pi\n",
    "        self.T = self.L/self.U_rms\n",
    "        \n",
    "        # collocation + data points\n",
    "        self.x_eqs = torch.tensor(x_eqs, requires_grad=True).float().to(device)\n",
    "        self.y_eqs = torch.tensor(y_eqs, requires_grad=True).float().to(device)\n",
    "        self.t_eqs = torch.tensor(t_eqs, requires_grad=True).float().to(device)\n",
    "              \n",
    "        # settings\n",
    "        self.upd_freq = upd_freq\n",
    "        self.weight = weight\n",
    "        self.device = device\n",
    "        self.amp = amp\n",
    "        \n",
    "        if self.amp and (device == \"cpu\"):\n",
    "            raise RuntimeError(\n",
    "                \"AMP is a CUDA feature, but your device appears to be a CPU.\"\n",
    "            )\n",
    "        \n",
    "        self.lambda_1 = torch.tensor([0.0], requires_grad=True).to(device)\n",
    "        self.lambda_2 = torch.tensor([-3.0], requires_grad=True).to(device)\n",
    "        \n",
    "        self.lambda_1 = torch.nn.Parameter(self.lambda_1)\n",
    "        self.lambda_2 = torch.nn.Parameter(self.lambda_2)\n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers_dnn).to(device)\n",
    "        self.dnn2 = DNN2(layers_dnn2).to(device)        \n",
    "        self.dnn2.register_parameter('lambda_1', self.lambda_1)\n",
    "        self.dnn2.register_parameter('lambda_2', self.lambda_2)        \n",
    "        self.iter = 0\n",
    "        \n",
    "    def net_uvp(self, x, y, t):  \n",
    "        uvp = self.dnn(torch.cat([x, y, t], dim=1))\n",
    "        u = uvp[:,0:1]\n",
    "        v = uvp[:,1:2]\n",
    "        p = uvp[:,2:3]        \n",
    "        return u, v, p\n",
    "    \n",
    "    def net_force(self, x, y):\n",
    "        force = self.dnn2(torch.cat([x, y], dim=1))\n",
    "        fx = force[:,0:1]\n",
    "        fy = force[:,1:2]\n",
    "        return fx, fy\n",
    "    \n",
    "    def net_NS(self, x, y, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        lambda_1 = torch.exp(self.lambda_1)        \n",
    "        lambda_2 = torch.exp(self.lambda_2)\n",
    "        u, v, p = self.net_uvp(x, y, t)\n",
    "        fx, fy = self.net_force(x, y)\n",
    "        \n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "             \n",
    "        u_y = torch.autograd.grad(\n",
    "            u, y, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_yy = torch.autograd.grad(\n",
    "            u_y, y, \n",
    "            grad_outputs=torch.ones_like(u_y),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v_t = torch.autograd.grad(\n",
    "            v, t, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v_x = torch.autograd.grad(\n",
    "            v, x, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v_y = torch.autograd.grad(\n",
    "            v, y, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v_xx = torch.autograd.grad(\n",
    "            v_x, x, \n",
    "            grad_outputs=torch.ones_like(v_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        v_yy = torch.autograd.grad(\n",
    "            v_y, y, \n",
    "            grad_outputs=torch.ones_like(v_y),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        p_x = torch.autograd.grad(\n",
    "            p, x, \n",
    "            grad_outputs=torch.ones_like(p),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        p_y = torch.autograd.grad(\n",
    "            p, y, \n",
    "            grad_outputs=torch.ones_like(p),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        fx_x = torch.autograd.grad(\n",
    "            fx, x, \n",
    "            grad_outputs=torch.ones_like(fx),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        fy_y = torch.autograd.grad(\n",
    "            fy, y, \n",
    "            grad_outputs=torch.ones_like(fy),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "              \n",
    "        f_u = (u_t + (u*u_x + v*u_y) + p_x + lambda_1*u - lambda_2*(u_xx + u_yy) - fx)*self.T/self.U_rms\n",
    "        f_v = (v_t + (u*v_x + v*v_y) + p_y + lambda_1*v - lambda_2*(v_xx + v_yy) - fy)*self.T/self.U_rms\n",
    "        f_div = (u_x + v_y)*self.L/self.U_rms\n",
    "        f2_div = (fx_x + fy_y)*(self.L/self.U_rms)*(self.L/self.U_rms)\n",
    "\n",
    "        return f_u, f_v, f_div, f2_div\n",
    "    \n",
    "    def plot_loss(self, loss, lambdas, optimizer):\n",
    "        clear_output(wait=True)\n",
    "        display(self.prbar.container)\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        epochs_ = np.arange(0, 100 * (len(loss)), 100)\n",
    "        \n",
    "        ax1.plot(epochs_, loss, color=\"C0\")\n",
    "        ax1.set_yscale(\"log\")\n",
    "        ax1.set_ylabel(\"loss\")\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "\n",
    "        ax2.plot(\n",
    "            epochs_,\n",
    "            np.abs(np.array(lambdas[0]) - 0.1) / 0.1 * 100,\n",
    "            color=\"C1\",\n",
    "            label=r\"Error $\\alpha$\",\n",
    "        )\n",
    "        ax2.set_ylabel(r\"Error $\\alpha$, %\")\n",
    "        ax2.set_xlabel(\"epoch\")\n",
    "        ax2.set_yscale(\"log\")\n",
    "        \n",
    "        ax3.plot(\n",
    "            epochs_,\n",
    "            np.abs(np.array(lambdas[1]) - 0.01) / 0.01 * 100,\n",
    "            color=\"C2\",\n",
    "            label=r\"Error $\\nu$\",\n",
    "        )\n",
    "        ax3.set_ylabel(r\"Error $\\nu$, %\")\n",
    "        ax3.set_xlabel(\"epoch\")\n",
    "        ax3.set_yscale(\"log\")\n",
    "        \n",
    "        fig.suptitle(str(optimizer) + \" train graphs\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def loss_func(self):\n",
    "        u_data, v_data, p_data = self.net_uvp(self.x, self.y, self.t)\n",
    "        loss_mse = torch.mean((self.u - u_data)**2 + (self.v - v_data)**2)/(self.U_rms**2)\n",
    "        \n",
    "        f_u_eqs, f_v_eqs, f_div_eqs, f2_div_eqs = self.net_NS(self.x_eqs, self.y_eqs, self.t_eqs)\n",
    "        loss_eqs = torch.mean(f_u_eqs**2 + f_v_eqs**2 + f_div_eqs**2 + f2_div_eqs**2)\n",
    "        \n",
    "        loss = loss_mse + self.weight*loss_eqs\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        if self.iter % self.upd_freq == 0:\n",
    "            if self.log == \"text\":\n",
    "                print(\n",
    "                    'It-LBFGS: %d, Loss: %e, alpha: %.3f, nu: %.5f' % \n",
    "                    (\n",
    "                        self.iter,\n",
    "                        loss.item(), \n",
    "                        torch.exp(self.lambda_1.detach()).item(), \n",
    "                        torch.exp(self.lambda_2.detach()).item()\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.losses_lbfgs.append(loss.detach().cpu().numpy())\n",
    "                self.lambdas_1_lbfgs.append(\n",
    "                    torch.exp(self.lambda_1.detach().cpu()).numpy()\n",
    "                )\n",
    "                self.lambdas_2_lbfgs.append(\n",
    "                    torch.exp(self.lambda_2.detach().cpu()).numpy()\n",
    "                )\n",
    "                self.plot_loss(\n",
    "                    loss=self.losses_lbfgs,\n",
    "                    lambdas=(self.lambdas_1_lbfgs, self.lambdas_2_lbfgs),\n",
    "                    optimizer=\"L-BFGS\",\n",
    "                )\n",
    "                \n",
    "        self.iter += 1\n",
    "        self.prbar.update(1)\n",
    "        return loss\n",
    "    \n",
    "    def train_adam(self, nIter, learn_rate=1e-3, log=\"plot\"):\n",
    "        self.prbar = tqdm(iterable=range(nIter), leave=True)\n",
    "        self.prbar.set_description(\"Epoch\")\n",
    "        \n",
    "        self.dnn.train()\n",
    "        self.dnn2.train()\n",
    "        self.optimizer_Adam = torch.optim.Adam(list(self.dnn.parameters())+list(self.dnn2.parameters()), lr=learn_rate)\n",
    "        \n",
    "        #scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer_Adam, \n",
    "        #                                                 milestones=[30000, 80000], gamma=0.5)\n",
    "        \n",
    "        self.losses_Adam = []\n",
    "        self.lambdas_1_Adam = []\n",
    "        self.lambdas_2_Adam = []\n",
    "        \n",
    "        if self.amp:\n",
    "            scaler = GradScaler()\n",
    "        \n",
    "        for epoch in self.prbar:\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            if self.amp:\n",
    "                with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "                    u_data, v_data, p_data = self.net_uvp(self.x, self.y, self.t)\n",
    "                    loss_mse = torch.mean((self.u - u_data)**2 + (self.v - v_data)**2)/(self.U_rms**2)\n",
    "                    \n",
    "                    f_u_eqs, f_v_eqs, f_div_eqs, f2_div_eqs = self.net_NS(self.x_eqs, self.y_eqs, self.t_eqs)\n",
    "                    loss_eqs = torch.mean(f_u_eqs**2 + f_v_eqs**2 + f_div_eqs**2 + f2_div_eqs**2)\n",
    "                    \n",
    "                    loss = loss_mse + self.weight*loss_eqs\n",
    "            \n",
    "                    self.optimizer_Adam.zero_grad(set_to_none=True)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer_Adam)\n",
    "                    scaler.update()\n",
    "            else:\n",
    "                u_data, v_data, p_data = self.net_uvp(self.x, self.y, self.t)\n",
    "                loss_mse = torch.mean((self.u - u_data)**2 + (self.v - v_data)**2)/(self.U_rms**2)\n",
    "                    \n",
    "                f_u_eqs, f_v_eqs, f_div_eqs, f2_div_eqs = self.net_NS(self.x_eqs, self.y_eqs, self.t_eqs)\n",
    "                loss_eqs = torch.mean(f_u_eqs**2 + f_v_eqs**2 + f_div_eqs**2 + f2_div_eqs**2)\n",
    "                    \n",
    "                loss = loss_mse + self.weight*loss_eqs\n",
    "            \n",
    "                # Backward and optimize\n",
    "                self.optimizer_Adam.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                self.optimizer_Adam.step()\n",
    "                \n",
    "            #scheduler.step()\n",
    "            \n",
    "            if epoch % self.upd_freq == 0:\n",
    "                if log == \"text\":                \n",
    "                    print(\n",
    "                        'It-adam: %d, Loss: %.5e, alpha: %.3f, nu: %.5f' % \n",
    "                        (\n",
    "                            epoch, \n",
    "                            loss.item(), \n",
    "                            torch.exp(self.lambda_1).item(), \n",
    "                            torch.exp(self.lambda_2).item()\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    self.losses_Adam.append(loss.detach().cpu().numpy())\n",
    "                    self.lambdas_1_Adam.append(\n",
    "                        torch.exp(self.lambda_1).detach().cpu().numpy()\n",
    "                    )\n",
    "                    self.lambdas_2_Adam.append(\n",
    "                        torch.exp(self.lambda_2).detach().cpu().numpy()\n",
    "                    )\n",
    "                    self.plot_loss(\n",
    "                        loss=self.losses_Adam,\n",
    "                        lambdas=(self.lambdas_1_Adam, self.lambdas_2_Adam),\n",
    "                        optimizer=\"Adam\",\n",
    "                    )\n",
    "                    \n",
    "                \n",
    "\n",
    "    def train_lbfgs(self, log=\"plot\", max_iter=100000):\n",
    "        self.prbar = tqdm(iterable=range(max_iter), leave=True)\n",
    "        self.prbar.set_description(\"Epoch\")\n",
    "        \n",
    "        # optimizers: using the same settings\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            list(self.dnn.parameters())+list(self.dnn2.parameters()), \n",
    "            lr=1.0, \n",
    "            max_iter=max_iter, \n",
    "            history_size=100,\n",
    "            tolerance_grad=1e-7, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n",
    "        )\n",
    "        self.dnn.train()\n",
    "        self.dnn2.train()\n",
    "        \n",
    "        self.losses_lbfgs = []\n",
    "        self.lambdas_1_lbfgs = []\n",
    "        self.lambdas_2_lbfgs = []\n",
    "\n",
    "        self.log = log\n",
    "                        \n",
    "        # Backward and optimize\n",
    "        self.optimizer.step(self.loss_func)\n",
    "    \n",
    "    def predict(self, x_star, y_star, t_star):\n",
    "        \n",
    "        x = torch.tensor(x_star, requires_grad=True).float().to(device)\n",
    "        y = torch.tensor(y_star, requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(t_star, requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.dnn.eval()\n",
    "        self.dnn2.eval()\n",
    "        \n",
    "        u, v, p = self.net_uvp(x, y, t)\n",
    "        fx, fy = self.net_force(x, y)\n",
    "        f_u, f_v, f_div, f2_div = self.net_NS(x, y, t)\n",
    "        \n",
    "        u = u.detach().cpu().numpy()\n",
    "        v = v.detach().cpu().numpy()\n",
    "        p = p.detach().cpu().numpy()\n",
    "        fx = fx.detach().cpu().numpy()\n",
    "        fy = fy.detach().cpu().numpy()\n",
    "        f_u = f_u.detach().cpu().numpy()\n",
    "        f_v = f_v.detach().cpu().numpy()\n",
    "        f_div = f_div.detach().cpu().numpy()\n",
    "        f2_div = f2_div.detach().cpu().numpy()\n",
    "        \n",
    "        return u, v, p, fx, fy, f_u, f_v, f_div, f2_div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32cc06-ae17-4812-bdc5-7df0426b8fde",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667a770-da33-4fcd-a640-e28fcd3bab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible values of coordinates and time\n",
    "Nx = 256\n",
    "Ny = 256\n",
    "T = 200\n",
    "\n",
    "grid_x = np.linspace(-np.pi, 0, Nx, endpoint=False)\n",
    "grid_y = np.linspace(-np.pi, 0, Ny, endpoint=False)\n",
    "grid_t = np.linspace(0, 4, T, endpoint=False)\n",
    "\n",
    "N_train = 30000\n",
    "N_col = 60000\n",
    "\n",
    "# random sampling\n",
    "idx = [randint(0, Nx-1) for p in range(N_train)]\n",
    "idy = [randint(0, Ny-1) for p in range(N_train)]\n",
    "idt = [randint(0, T-1) for p in range(N_train)]\n",
    "\n",
    "idx2 = [randint(0, Nx-1) for p in range(N_col)]\n",
    "idy2 = [randint(0, Ny-1) for p in range(N_col)]\n",
    "idt2 = [randint(0, T-1) for p in range(N_col)]\n",
    "\n",
    "# training dataset\n",
    "x_train = grid_x[idx][:, None]\n",
    "y_train = grid_y[idy][:, None]\n",
    "t_train = grid_t[idt][:, None]\n",
    "u_train = dat_velx[idy, idx, np.array(idt)][:, None]\n",
    "v_train = dat_vely[idy, idx, np.array(idt)][:, None]\n",
    "\n",
    "# collocations points\n",
    "x_col = grid_x[idx2][:, None]\n",
    "y_col = grid_y[idy2][:, None]\n",
    "t_col = grid_t[idt2][:, None]\n",
    "\n",
    "# eqs points = train + col points\n",
    "x_eqs = np.vstack((x_train, x_col))\n",
    "y_eqs = np.vstack((y_train, y_col))\n",
    "t_eqs = np.vstack((t_train, t_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc490c-c24e-4e7a-9a43-a6deaa470bc2",
   "metadata": {},
   "source": [
    "### Application of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234a663-640c-4b8c-afe1-c6dd70909839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps = 0.005\n",
    "\n",
    "factor_u = 1 + eps*np.random.randn(N_train,1)\n",
    "factor_v = 1 + eps*np.random.randn(N_train,1)\n",
    "\n",
    "u_train_noise = u_train*factor_u\n",
    "v_train_noise = v_train*factor_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c09c9-5371-4cce-98b2-8dfe2474be85",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34433416-7e91-4944-862e-e02ffe48a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dnn = [3, 250, 250, 250, 250, 250, 250, 250, 3]\n",
    "layers_dnn2 = [2, 30, 30, 30, 30, 30, 2]\n",
    "\n",
    "model = PhysicsInformedNN(x_train, y_train, t_train, u_train_noise, v_train_noise, x_eqs, y_eqs, t_eqs,\n",
    "                          layers_dnn, layers_dnn2, device=device, amp=True, weight=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa425d-1fba-4b4b-b184-b5016c0e5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_adam(100001, 1e-3, log='plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de35ea-afe1-4000-b90f-d02b71dce360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_lbfgs(log='plot', max_iter=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13bae1-a193-4e94-a238-bea1e61b1b93",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4b90f-eced-491e-b9e4-a77bacdc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.dnn.state_dict(), './saved_models/A01_dnn_250_7_30_5_30+60k_s46_n05.pth')\n",
    "torch.save(model.dnn2.state_dict(), './saved_models/A01_dnn2_250_7_30_5_30+60k_s46_n05.pth')\n",
    "torch.save([model.lambda_1, model.lambda_2], './saved_models/A01_params_250_7_30_5_30+60k_s46_n05.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5491c-5731-4335-a0fa-0d13618de690",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5dea9c-da0a-4fed-899e-6bef0b487d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dnn.load_state_dict(torch.load('./saved_models/A01_dnn_250_7_30_5_30+60k_s41.pth'))\n",
    "model.dnn2.load_state_dict(torch.load('./saved_models/A01_dnn2_250_7_30_5_30+60k_s41.pth'))\n",
    "[model.lambda1, model.lambda2] = torch.load('./saved_models/A01_params_250_7_30_5_30+60k_s41.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d057bd6-d094-4bbf-a627-8565d5546158",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prediction & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f4e33-71e8-418c-801e-9b521fad70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_velocity = np.zeros(T)\n",
    "error_pressure = np.zeros(T)\n",
    "\n",
    "time_step = 0.02\n",
    "\n",
    "X, Y = np.meshgrid(grid_x,grid_y)\n",
    "\n",
    "x_star = X.flatten()[:, None]\n",
    "y_star = Y.flatten()[:, None]\n",
    "X_star = np.hstack((x_star,y_star))\n",
    "\n",
    "for i in range(T):\n",
    "    time = i*time_step\n",
    "    frame = i    \n",
    "    \n",
    "    t_star = x_star*0+time\n",
    "    \n",
    "    u_star = dat_velx[0:Ny, 0:Nx, frame]\n",
    "    v_star = dat_vely[0:Ny, 0:Nx, frame]\n",
    "    p_star = dat_p[0:Ny, 0:Nx, frame]\n",
    "\n",
    "    UU_exact = griddata(X_star, u_star.flatten(), (X, Y), method='nearest')\n",
    "    VV_exact = griddata(X_star, v_star.flatten(), (X, Y), method='nearest')\n",
    "    PP_exact = griddata(X_star, p_star.flatten(), (X, Y), method='nearest')\n",
    "    \n",
    "    # prediction\n",
    "    u_pred, v_pred, p_pred, fx_pred, fy_pred, \\\n",
    "            fu_pred, fv_pred, fdiv_pred, f2div_pred = model.predict(x_star, y_star, t_star)\n",
    "\n",
    "    UU_pred = griddata(X_star, u_pred.flatten(), (X, Y), method='nearest')\n",
    "    VV_pred = griddata(X_star, v_pred.flatten(), (X, Y), method='nearest')\n",
    "    PP_pred = griddata(X_star, p_pred.flatten(), (X, Y), method='nearest')\n",
    "    \n",
    "    error_velocity[i] = np.sqrt(np.mean((UU_pred-UU_exact)**2 + (VV_pred-VV_exact)**2)/np.mean(UU_exact**2 + VV_exact**2))\n",
    "    error_pressure[i] = np.linalg.norm(p_star.flatten()-np.mean(p_star.flatten())-p_pred.flatten()+np.mean(p_pred.flatten()),2)/np.linalg.norm(p_star.flatten()-np.mean(p_star.flatten()),2)\n",
    "\n",
    "lambda_1_value = model.lambda_1.detach().cpu().numpy()\n",
    "lambda_2_value = model.lambda_2.detach().cpu().numpy()\n",
    "lambda_1_value = np.exp(lambda_1_value)\n",
    "lambda_2_value = np.exp(lambda_2_value)\n",
    "error_lambda_1 = np.abs(lambda_1_value - 0.1)/0.1 * 100\n",
    "error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
    "\n",
    "print('Error velocity: %.5f%%' % (np.mean(error_velocity)*100))    \n",
    "print('Error pressure: %.5f%%' % (np.mean(error_pressure)*100))  \n",
    "print('Error alpha: %.5f%%' % (error_lambda_1))                             \n",
    "print('Error nu: %.5f%%' % (error_lambda_2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3eb4ee-2918-4b87-9c16-b598270dffe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Error Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12042967-28d0-48d0-bdd2-f0510f5791c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "time = np.array([3.0]) # от 0 до 3.98 c шагом 0.02\n",
    "frame=(np.rint(time/0.02)).astype(int)\n",
    "\n",
    "X, Y = np.meshgrid(grid_x,grid_y)\n",
    "\n",
    "x_star = X.flatten()[:, None]\n",
    "y_star = Y.flatten()[:, None]\n",
    "t_star = x_star*0+time\n",
    "\n",
    "X_star = np.hstack((x_star,y_star))\n",
    "\n",
    "u_star = dat_velx[0:Ny, 0:Nx, frame]\n",
    "v_star = dat_vely[0:Ny, 0:Nx, frame]\n",
    "p_star = dat_p[0:Ny, 0:Nx, frame]\n",
    "\n",
    "UU_exact = griddata(X_star, u_star.flatten(), (X, Y), method='nearest')\n",
    "VV_exact = griddata(X_star, v_star.flatten(), (X, Y), method='nearest')\n",
    "PP_exact = griddata(X_star, p_star.flatten(), (X, Y), method='nearest')\n",
    "\n",
    "# prediction\n",
    "u_pred, v_pred, p_pred, fx_pred, fy_pred, \\\n",
    "            fu_pred, fv_pred, fdiv_pred, f2div_pred = model.predict(x_star, y_star, t_star)\n",
    "\n",
    "UU_pred = griddata(X_star, u_pred.flatten(), (X, Y), method='nearest')\n",
    "VV_pred = griddata(X_star, v_pred.flatten(), (X, Y), method='nearest')\n",
    "PP_pred = griddata(X_star, p_pred.flatten(), (X, Y), method='nearest')\n",
    "FFX_pred = griddata(X_star, fx_pred.flatten(), (X, Y), method='nearest')\n",
    "FFY_pred = griddata(X_star, fy_pred.flatten(), (X, Y), method='nearest')\n",
    "\n",
    "error_vel = np.sqrt(np.mean((UU_pred-UU_exact)**2 + (VV_pred-VV_exact)**2)/np.mean(UU_exact**2 + VV_exact**2))\n",
    "error_p = np.linalg.norm(p_star.flatten()-np.mean(p_star.flatten())-p_pred.flatten()+np.mean(p_pred.flatten()),2)/np.linalg.norm(p_star.flatten()-np.mean(p_star.flatten()),2)\n",
    "\n",
    "print('Error vel: %.5f%%' % (error_vel*100))    \n",
    "print('Error p: %.5f%%' % (error_p*100))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864d29a-c110-472f-963d-ecb6a2e59e52",
   "metadata": {},
   "source": [
    "### Analysis of the force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24782e58-9ff4-49af-b3fa-835119d190bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_x(x, y):\n",
    "    return 10*np.sin(5*y)\n",
    "\n",
    "def force_y(x, y):\n",
    "    return 0*x+0*y\n",
    "\n",
    "FFX_exact = force_x(X, Y)\n",
    "FFY_exact = force_y(X, Y)\n",
    "\n",
    "error_f = np.sqrt(np.mean((FFX_pred-FFX_exact)**2 + (FFY_pred-FFY_exact)**2)/np.mean(FFX_exact**2 + FFY_exact**2))\n",
    "print('Error f: %.5f%%' % (error_f*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2b7b6-f383-4b85-8a23-4f556e4238f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Error Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487256e-ea5d-4bf0-8d89-827bad21de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 17))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.remove()\n",
    "\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
    "\n",
    "########     Exact Vel-X     ########### \n",
    "gs2 = gridspec.GridSpec(3, 1)\n",
    "gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.2)\n",
    "ax = plt.subplot(gs2[0, :])\n",
    "limit = max(abs(np.min(UU_exact)), abs(np.max(UU_exact)))\n",
    "h = ax.imshow(UU_exact, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-4, 0, 4])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Exact Vel-X', fontsize = 15)\n",
    "\n",
    "########     Predicted Vel-X     ########### \n",
    "ax = plt.subplot(gs2[1, :])\n",
    "h = ax.imshow(UU_pred, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-4, 0, 4])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted Vel-X', fontsize = 15)\n",
    "\n",
    "########     Difference Vel-X     ########### \n",
    "ax = plt.subplot(gs2[2, :])\n",
    "h = ax.imshow(UU_exact - UU_pred, cmap='seismic', vmin=-limit/100, vmax=limit/100,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-0.04, 0, 0.04])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Difference Vel-X', fontsize = 15)\n",
    "\n",
    "#plt.savefig('./Vx.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99221ac-866c-4e33-8b24-c4c2699c6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 17))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.remove()\n",
    "\n",
    "########     Exact Vel-Y     ########### \n",
    "gs2 = gridspec.GridSpec(3, 1)\n",
    "gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.2)\n",
    "ax = plt.subplot(gs2[0, :])\n",
    "limit = max(abs(np.min(VV_exact)), abs(np.max(VV_exact)))\n",
    "h = ax.imshow(VV_exact, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-4, 0, 4])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Exact Vel-Y', fontsize = 15)\n",
    "\n",
    "########     Predicted Vel-Y     ########### \n",
    "ax = plt.subplot(gs2[1, :])\n",
    "h = ax.imshow(VV_pred, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-4, 0, 4])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted Vel-Y', fontsize = 15)\n",
    "\n",
    "########     Difference Vel-Y     ########### \n",
    "ax = plt.subplot(gs2[2, :])\n",
    "h = ax.imshow(VV_exact - VV_pred, cmap='seismic', vmin=-limit/100, vmax=limit/100,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-0.04, 0, 0.04])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted Vel-Y', fontsize = 15)\n",
    "\n",
    "#plt.savefig('./Vy.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa84908-df04-437d-b03b-be076649301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 17))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.remove()\n",
    "\n",
    "########     Exact Pressure     ########### \n",
    "gs2 = gridspec.GridSpec(3, 1)\n",
    "gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, hspace=0.2)\n",
    "ax = plt.subplot(gs2[0, :])\n",
    "limit = max(abs(np.min(PP_exact-np.mean(PP_exact))), abs(np.max(PP_exact-np.mean(PP_exact))))\n",
    "h = ax.imshow(PP_exact-np.mean(PP_exact), cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Exact Pressure', fontsize = 15)\n",
    "\n",
    "########     Predicted Pressure     ########### \n",
    "ax = plt.subplot(gs2[1, :])\n",
    "h = ax.imshow(PP_pred-np.mean(PP_pred), cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted Pressure', fontsize = 15)\n",
    "\n",
    "########     Difference      ########### \n",
    "ax = plt.subplot(gs2[2, :])\n",
    "h = ax.imshow(PP_pred-np.mean(PP_pred)-PP_exact+np.mean(PP_exact), cmap='seismic', vmin=-limit/10, vmax=limit/10,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Difference Pressure', fontsize = 15)\n",
    "\n",
    "#plt.savefig('./P.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d603d5e-f366-41a3-aba0-402153a02f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 17))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.remove()\n",
    "\n",
    "########     Exact FFX     ########### \n",
    "gs2 = gridspec.GridSpec(3, 1)\n",
    "gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.2)\n",
    "ax = plt.subplot(gs2[0, :])\n",
    "limit = max(abs(np.min(FFX_exact)), abs(np.max(FFX_exact)))\n",
    "h = ax.imshow(FFX_exact, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-10,0,10])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Exact F_X', fontsize = 15)\n",
    "\n",
    "########     Predicted FFX     ########### \n",
    "ax = plt.subplot(gs2[1, :])\n",
    "h = ax.imshow(FFX_pred, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-10,0,10])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted F_X', fontsize = 15)\n",
    "\n",
    "########     Difference FFX     ########### \n",
    "ax = plt.subplot(gs2[2, :])\n",
    "h = ax.imshow(FFX_exact - FFX_pred, cmap='seismic', vmin=0.0, vmax=0.5,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[0,0.25,0.5])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Difference F_X', fontsize = 15)\n",
    "\n",
    "#plt.savefig('./Fx.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b028094-ac97-44f3-889f-efb2c96c08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 17))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.remove()\n",
    "\n",
    "########     Exact FFY     ########### \n",
    "gs2 = gridspec.GridSpec(3, 1)\n",
    "gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.2)\n",
    "ax = plt.subplot(gs2[0, :])\n",
    "#limit = max(abs(np.min(FFY_pred)), abs(np.max(FFY_pred)))\n",
    "limit = max(abs(np.min(FFX_exact)), abs(np.max(FFX_exact)))\n",
    "h = ax.imshow(FFY_exact, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-10,0,10])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Exact F_Y', fontsize = 15)\n",
    "\n",
    "########     Predicted FFY     ########### \n",
    "ax = plt.subplot(gs2[1, :])\n",
    "h = ax.imshow(FFY_pred, cmap='seismic', vmin=-limit, vmax=limit,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[-10, 0, 10])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Predicted F_Y', fontsize = 15)\n",
    "\n",
    "########     Difference FFY     ########### \n",
    "ax = plt.subplot(gs2[2, :])\n",
    "h = ax.imshow(FFY_exact - FFY_pred, cmap='seismic', vmin=0.2, vmax=0.3,\n",
    "              extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "fig.colorbar(h, cax=cax, ticks=[0.2, 0.25, 0.3])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_yticks(np.arange(-3, 0.1, step=1))\n",
    "ax.set_aspect('equal', 'box')\n",
    "#ax.set_title('Difference F_Y', fontsize = 15)\n",
    "\n",
    "#plt.savefig('./Fy.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a92b6-0d0f-4cbe-a4fe-017b318a8302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
